{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install efficientnet\n!pip install livelossplot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import necessary libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport PIL\nfrom IPython.display import Image, display\nfrom keras.applications.vgg16 import VGG16,preprocess_input\n# Plotly for the interactive viewer (see last section)\nimport plotly.graph_objs as go\nimport plotly.graph_objects as go\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential, Model,load_model\nfrom keras.applications.vgg16 import VGG16,preprocess_input\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten,BatchNormalization,Activation, Input\nfrom tensorflow.keras.layers import GlobalMaxPooling2D\nfrom keras.models import Model\nfrom keras.optimizers import Adam, SGD, RMSprop\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport gc\nimport skimage.io\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.python.keras import backend as K\nimport efficientnet.tfkeras as efn\nfrom livelossplot import PlotLossesKeras","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Exploration"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_dir = \"/kaggle/input/siim-isic-melanoma-classification/jpeg/train/\"\ntest_dir = \"/kaggle/input/siim-isic-melanoma-classication/jpeg/train/\"\ntrain = pd.read_csv(\"/kaggle/input/siim-isic-melanoma-classification/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/siim-isic-melanoma-classification/test.csv\")\nsubmission = pd.read_csv(\"/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = train[\"benign_malignant\"].value_counts().index\nvalues = train[\"benign_malignant\"].value_counts().values\n\ntrace = go.Pie(labels=labels, values=values)\ngo.Figure(data=[trace])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dataset is unbalanced"},{"metadata":{"trusted":true},"cell_type":"code","source":"trace_benign = go.Box(y=train.query(\"benign_malignant=='benign'\")[\"age_approx\"], name=\"benign\")\ntrace_malignant = go.Box(y=train.query(\"benign_malignant=='malignant'\")[\"age_approx\"], name=\"malignant\")\ndata = [trace_benign, trace_malignant]\nlayout = go.Layout(title=\"age vs benign\", xaxis_title=\"benign_malignant\", yaxis_title=\"age\")\ngo.Figure(data, layout)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cannot see very much difference for age group"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = train[\"anatom_site_general_challenge\"].value_counts().index\nvalues = train[\"anatom_site_general_challenge\"].value_counts().values\ntrace = go.Pie(labels=labels, values=values, textinfo=\"label+percent\", insidetextorientation=\"radial\")\nfig = go.Figure(data=[trace])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cb = pd.crosstab(train[\"anatom_site_general_challenge\"], train[\"benign_malignant\"])\ncb[\"ratio\"] = cb['benign'] / cb['malignant']\ncb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Different anatom_site_general_challenge has different probability lead to the malignant"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = train[\"diagnosis\"].value_counts().index\nvalues = train[\"diagnosis\"].value_counts().values\ntrace = go.Pie(labels=labels, values=values, textinfo=\"label+percent\", insidetextorientation=\"radial\")\nfig = go.Figure(data=[trace])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cb = pd.crosstab(train[\"diagnosis\"], train[\"benign_malignant\"])\ncb[\"ratio\"] = cb[\"benign\"] / cb[\"malignant\"]\ncb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No wrong diagnoise"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_0 = train[train['target']==0].sample(2000)\ndf_1 = train[train['target']==1]\ntrain_downsample = pd.concat([df_0, df_1]).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"malignant = []\nsample = df_1.sample(40)\nfor i in sample.image_name:\n    img = cv2.imread(train_dir + i + '.jpg')\n    img = cv2.resize(img, (384, 384))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype('float32') / 255.\n    malignant.append(img)\nfx, ax = plt.subplots(5, 8, figsize=(10,8))\nfor i, img in enumerate(malignant):\n    ax[i//8, i%8].imshow(img)\n    ax[i//8, i%8].axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = []\ndata = []\nfor i in range(train.shape[0]):\n    data.append(train_dir + train[\"image_name\"].iloc[i] + '.jpg')\n    labels.append(train[\"target\"].iloc[i])\ndf = pd.DataFrame(data)\ndf.columns = [\"images\"]\ndf[\"target\"] = labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data=[]\nfor i in range(test.shape[0]):\n    test_data.append(test_dir + test['image_name'].iloc[i]+'.jpg')\ndf_test=pd.DataFrame(test_data)\ndf_test.columns=['images']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Process the input data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(df['images'],df['target'], test_size=0.2, random_state=1234)\ntrain=pd.DataFrame(X_train)\ntrain.columns=['images']\ntrain['target']=y_train\n\nvalidation=pd.DataFrame(X_val)\nvalidation.columns=['images']\nvalidation['target']=y_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_epochs = 40\nbatch_size  = 16*8\nnb_train_steps = train.shape[0]//batch_size\nnb_val_steps=validation.shape[0]//batch_size\nprint(\"Number of training and validation steps: {} and {}\".format(nb_train_steps,nb_val_steps))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,horizontal_flip=True)\nval_datagen=ImageDataGenerator(rescale=1./255)\ntrain_generator = train_datagen.flow_from_dataframe(\n    train,\n    x_col='images',\n    y_col='target',\n    target_size=(384, 384),\n    batch_size=8,\n    shuffle=True,\n    class_mode='raw')\n\nvalidation_generator = val_datagen.flow_from_dataframe(\n    validation,\n    x_col='images',\n    y_col='target',\n    target_size=(384, 384),\n    shuffle=False,\n    batch_size=8,\n    class_mode='raw')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Effcientnet with resolution (384, 384)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def binary_focal_loss(gamma=2., alpha=.25):\n    \"\"\"\n    Binary form of focal loss.\n      FL(p_t) = -alpha * (1 - p_t)**gamma * log(p_t)\n      where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n    References:\n        https://arxiv.org/pdf/1708.02002.pdf\n    Usage:\n     model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n    \"\"\"\n    def binary_focal_loss_fixed(y_true, y_pred):\n        \"\"\"\n        :param y_true: A tensor of the same shape as `y_pred`\n        :param y_pred:  A tensor resulting from a sigmoid\n        :return: Output tensor.\n        \"\"\"\n        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n\n        epsilon = K.epsilon()\n        # clip to prevent NaN's and Inf's\n        pt_1 = K.clip(pt_1, epsilon, 1. - epsilon)\n        pt_0 = K.clip(pt_0, epsilon, 1. - epsilon)\n\n        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) \\\n               -K.sum((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n\n    return binary_focal_loss_fixed\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inp = tf.keras.layers.Input(shape = (384, 384, 3))\nefnetb3 = efn.EfficientNetB3(weights = 'imagenet', include_top = False)\nx = efnetb3(inp)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\noutput = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n\nmodel = tf.keras.models.Model(inputs = [inp], outputs = [output])\nopt = tf.keras.optimizers.Adam(learning_rate = 0.0003)\nmodel.compile(\n            optimizer = opt,\n            loss = [binary_focal_loss(gamma = 2.0, alpha = 0.80)],\n            metrics = [tf.keras.metrics.AUC()]\n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_auc', mode = 'max', patience = 5, \n                                                      verbose = 1, min_delta = 0.0001, restore_best_weights = True)\n\ncb_lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_auc', factor = 0.4, patience = 2, verbose = 1, min_delta = 0.0001, mode = 'max') \nmodel.fit_generator(train_generator,\n                   epochs=40,\n                   validation_data=validation_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target=[]\nfor path in df_test['images']:\n    img=cv2.imread(str(path))\n    img = cv2.resize(img, (384,384))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)/255.\n    img=np.reshape(img,(1,384,384,3))\n    prediction=model.predict(img)\n    target.append(prediction[0][0])\n\nsubmission['target']=target\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('sub_EfficientNetB3_384.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}